\documentclass[sigconf]{acmart}

\input{format/i523}

\begin{document}
\title{Big Data Applications for Vehicle Crash Prediction}


\author{Kevin Duffy}
\orcid{1234-5678-9012}
\affiliation{%
  \institution{Indiana University}
  \streetaddress{4014 E. Stop 10 Rd.}
  \city{Indianapolis} 
  \state{Indiana} 
  \postcode{46237}
}
\email{kevduffy@iu.edu}

% The default list of authors is too long for headers}
\renewcommand{\shortauthors}{K. Duffy}


\begin{abstract}
The idea of predicting car crashes used to be a fruitless endeavor - relegated to mere guesswork. However, advances in big data applications have allowed law enforcement to more accurately predict when and where car crashes are likely to occur, thus lowering first response times and taking proactive actions to prevent accidents in high-risk corridors. This paper shows several different approaches different agencies have taken using the power of data to solve this critical problem. 
\end{abstract}

\keywords{Big Data, Vehicles, Crashes, HID310, I523}


\maketitle



\section{Introduction}

Car crashes are the top cause of death for Americans between ages 5 and 34.\cite{gcn} Although the rate of car crashes has been dropping steadily over the last few decades \cite{iihs}, they remain a constant hazard for any who travel on our roads.

While most of the talk regarding car crashes and big data usually involves the development of self-driving cars (and understandably so), more immediate measures are being developed to meet this problem. A common usage of data in this domain is the prediction of high-risk crash areas.

The idea of predicting when and where crashes would occur used to be pure guesswork on the part of experienced police troopers\cite{pew}, but advances in big data analysis has allowed law enforcement agencies to begin predicting and mapping exactly when and where high-risk areas will occur. Advocates contend that these tools allow first responders to act more efficiently both reactively and proactively, making our roads safer on which to travel. 

We will outline the initial problem being addressed by these tools, the ultimate goal of such an exercise, and briefly explore two approaches to this solution. We will determine what outcomes these applications had, as well as whether they can be fully evaluated at this time. 

\section{Trends and Goals}
In 1975, the United States had a rate of 3.35 deaths per 100 million miles traveled.\cite{iihs} In 2015, that rate stood at 1.13 deaths. In fact, during that time frame, the amount of miles traveled on our roads has more than doubled, while the average annual number of fatalities on our roads has dropped by more than 10,000. The National Highway Traffic Safety Administration (NHTSA) credits this to the successful implementation of the Four Es of traffic safety:
\begin{itemize}
    \item Enforcement
    \item Engineering
    \item Education
    \item Emergency Medical Services \cite{gcn}
\end{itemize}
However, the NHTSA and other safety groups are not satisfied with merely lower numbers. They are driven by an initiative called Toward Zero Deaths which, as the name implies, strives toward the elimination of traffic related deaths.\cite{gcn} 

But how can highway safety groups reach this lofty goal? And what are they already doing about it? It should come as little surprise that the powerful utilization of big data has been rising in this field.

\section{Big Data Solutions}
A lot of data points can be collected from current activities undertaken through the Four Es. These include things such as traffic volume at the time of the crash, vehicle speed, road and construction conditions, and emergency response times. \cite{gcn}

In addition, state agencies have found that other extraneous factors contributed to the likelihood of a crash, such as events like football games, major holidays that correspond with an increase in drunk driving (such as New Year's Eve and Super Bowl Sunday), and concentrations of establishments that serve alcohol.\cite{pew} 

Unfortunately, these data points were previously siloed off in different agencies and formats, making dynamic usage of this information difficult if not impossible. However, some states are beginning to utilize this data in an effective way. They are beginning to collect data in a deliberate way so as to coordinate information between agencies in order to create applications and tools for use by troopers, other emergency response, road planners, and the public at large. \cite{pew}

States are going about this problem in different ways. This will allow us to approach the issue from different angles and see which approaches yield superior results. However, since these applications are still so new, it is not yet possible to fully evaluate their effectiveness on outcomes. This paper is examining two state approaches: Tennessee, which was one of the first initiatives in the nation, and Indiana, which was modeled after Tennessee's program in a more comprehensive way.

\subsection{Tennessee}
The origin of Tennessee Highway Patrol's Predictive Analytics program began in 2008, when state troopers switched from paper-and-pen crash reports to an electronic interface. This allowed Tennessee's agencies to use real-time data to create prediction software for car crashes. According to the State of Tennessee, the program uses SPSS software to apply three different statistical models with machine-learning algorithms in order to provide troopers with risk areas for certain types of crashes. \cite{tennessee} The models used were:
\begin{enumerate}
    \item Crash Reduction Analyzing Statistical History (CRASH). Using risk factors and historical crash data, this model gives probabilities on a fatal or injury-causing accident over four-hour blocks over a one week period, which is then illustrated on interactive maps.
    \item Driving Under the Influence (DUI). Calculates the probability of a crash related to a DUI from 4 pm to 4 am. 
    \item Commercial Motor Vehicle (CMV). Calculates the probability of a crash related to a commercial motor vehicle (such as a semi truck).\cite{tennessee}
\end{enumerate}
The program was implemented in 2013. Using this technology, troopers stationed themselves in more statistically advantageous positions in order to decrease response times to crashes, and take preliminary actions to prevent crashes such as setting up traffic direction or more aggressive enforcement on speeding and reckless driving. 

From 2013 to 2015, Tennessee traffic deaths fell 3 percent, compared to a 7 percent increase across the nation. This cannot yet be directly tied to the performance of the program, but according to officials such as the THP Statistics official Patrick Dolan, the effect is clear.

Information coming out of the Predictive Analytics program driving targeted enforcement ''has allowed us to deploy our resources more effectively to execute our mission successfully,`` Dolan reported to the Tennessee government's Traffic Safety Innovations 2016 newsletter. \cite{tennessee}

However, the trend became murkier in 2016. Tennessee traffic deaths spiked 8 percent, matching the national trend. Officials are still unclear whether the model is to blame. According to Dolan, average police response time dropped nearly 33 percent between 2012 and 2016. \cite{pew}

\subsection{Indiana}
In March 2014, then-Indiana Governor Mike Pence create by executive order the Management Performance Hub (MPH), a subagency tasked with driving ''a coordinated effort by state agencies to share data and improve and strengthen services, maximize the utilization of available resources, and ensure that state services are available to all Hoosiers.``\cite{pence}

One of the first projects undertaken by MPH was the Crash Prediction Website. Inspired by Tennessee's program\cite{govtech}, the MPH worked in tandem with the Indiana State Police to create an interactive map (Figure 1) showing the probability of both fatal and nonfatal traffic accidents. 

\begin{figure}
\includegraphics[width=\columnwidth]{images/indcrashmap.jpg}
\caption{The map shows the probability of a crash through color-coded blocks.\cite{indcrashmap}}
\end{figure}

The model grew out of several factors:
\begin{enumerate}
    \item The concept was borrowed from Tennessee's aforementioned Predictive Analytics program, though Indiana had a greater range and depth of data available. 
    \item The core of the model is built upon data from 2 million crashes going back to 2004. The data was cleaned so only relevant crash data was included in the forecast.
    \item The probability of a car crash is ranked from ''very low risk`` to ''high risk``, which is then indicated on the map through color-colded 1 square kilometer blocks over three hour time blocks.\cite{statescoop} This is more granular than Tennessee's maps, in both time and space scale. These probabilities are ranked based off of weather forecasts, traffic congestion, road conditions, time of day, historical information, and census data. 
    \item The map is populated with different colored dots to represent past car crashes - red for injury-causing, grey for non-injuries. Users can then click these to identify unique details of actual car crashes.\cite{govtech}
    \item The model is updated automatically with fresh crash reports, providing the software with dynamic information.
\end{enumerate}

Unlike Tennessee's program, Indiana's crash map is completely available to the public for their own personal use, though its usage will primarily be used by police and first responders. 

Although it is still too soon after launch to evaluate the effectiveness of this model, Indiana officials are optimistic. Indiana's Office of Management and Budget, the parent agency to the MPH, estimates that even a one percent reduction in Indiana crashes could net up to \$30 million in annual savings, besides the obvious benefits of fewer road casualties. 

With the groundwork laid in the crash map, officials are hoping to utilize the technology in other ways. Major Michael White of the Indiana State Police, in an interview with Statescoop.com, said with the technology developed through this initiative, they hope to move on to using it to map crime data as well.\cite{statescoop}

\section{Conclusion}
While these applications and initiatives are still too new to fully evaluate, there does appear to be preliminary results that show promise. 

Tennessee showed quick decline in car crashes and police response times, while Indiana built upon Tennessee's example to provide a more comprehensive look at all risk factors involved in a car crash, while opening this tool up to the public for personal use. 

These applications also show promise in application to other domains, such as the Indiana State Police's interest in creating a crime risk map using the same principles. 

It is also encouraging to view these as an example in various state agencies coordinating in order to share data and collaborate on applications. If Indiana's Management Performance Hub is any indication, these collaborations will continue, at least in Indiana. Hopefully more states follow suit in creating data sharing hubs and protocols in order to streamline government data utilization.

Ultimately, what is primarily needed is more time to evaluate the effectiveness of these initiatives, as well as metadata related to utilization of the map (for example, what is the average response times of a trooper using the map versus one who is not using the map). As more states grow their own initiatives, we can also evaluate whether certain approaches are more effective than others.

\begin{acks}

  The author would like to thank Dr. Gregor von Laszewski and all TA's for their tireless work in ensuring this class goes smoothly.

\end{acks}

\bibliographystyle{ACM-Reference-Format}
\bibliography{report} 

\appendix

\input{issues}

\end{document}
